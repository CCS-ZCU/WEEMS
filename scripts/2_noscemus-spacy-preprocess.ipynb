{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "566b19ef31a827cc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Description\n",
    "\n",
    "In this notebookm we employ `latincy` (SpaCy NLP model for latin  - see Burns, P. J. (2023). LatinCy: Synthetic Trained Pipelines for Latin NLP. https://doi.org/10.48550/ARXIV.2305.04365) to make an automatic (neural-networks driven) language annotation of all texts in noscemus. To improve the results, we first do some cleaning of the texts. We also have to develop a specific approach to deal with large text files, which cannot be processed by SpaCy at once.\n",
    "\n",
    "* INPUT: text files in the \"noscemus_raw\" subdirectory\n",
    "* OUTPUT: json files in the \"noscemus_spacyjsons_v1\" subdirectory (WARNING: large folder, more than 20 GB in total) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc8098de77557c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Spacy setup (run only for first time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28136ccf81624019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:18:19.497851Z",
     "start_time": "2024-07-26T11:18:14.804909Z"
    }
   },
   "outputs": [],
   "source": [
    "#!wget https://huggingface.co/latincy/la_core_web_lg/resolve/main/la_core_web_lg-any-py3-none-any.whl\n",
    "#!mv la_core_web_lg-any-py3-none-any.whl la_core_web_lg-3.7.6-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5bad77186dbf7cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:33:48.160642Z",
     "start_time": "2024-07-26T11:31:52.230088Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/srv/venvs/latin_venv/bin/python -m pip install la_core_web_lg-3.7.6-py3-none-any.whl --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0a5b1532dba641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:03:50.211781Z",
     "start_time": "2024-07-26T12:03:50.038509Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#!rm  la_core_web_lg-3.7.6-py3-none-any.whl"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "print(\"hello\")",
   "id": "56bcf0cb29daa97f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "911b5208-c6cb-4aaa-afbd-d1db08ec7211",
   "metadata": {},
   "source": [
    "# Start here"
   ]
  },
  {
   "cell_type": "code",
   "id": "b098c715-50e1-443e-8980-872f89efb463",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import spacy\n",
    "import os\n",
    "import glob\n",
    "from spacy.tokens import Doc\n",
    "from spacy.language import Language\n",
    "import pickle\n",
    "from unidecode import unidecode\n",
    "import sddk\n",
    "import pandas as pd\n",
    "import re\n",
    "import cupy\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f09f686b-3031-4674-af2d-c42dd1bd3bcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T08:38:36.731509Z",
     "start_time": "2024-11-06T08:38:36.726586Z"
    }
   },
   "source": [
    "try:\n",
    "    # Check if GPU is available\n",
    "    spacy.require_gpu()\n",
    "\n",
    "    # Verify CuPy can initialize the GPU\n",
    "    cupy_array = cupy.zeros((10, 10))\n",
    "    print(\"CuPy is able to use the GPU.\")\n",
    "\n",
    "    print(\"GPU is available for SpaCy.\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"Unable to use GPU for SpaCy: {e}\")\n",
    "except Exception as ex:\n",
    "    print(f\"An error occurred: {ex}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy is able to use the GPU.\n",
      "GPU is available for SpaCy.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "5872e40f-610e-4ebb-9d4f-794fc47820b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T08:38:20.719385Z",
     "start_time": "2024-11-06T08:38:20.711298Z"
    }
   },
   "source": [
    "spacy.require_gpu() "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "4f8a705cb29692c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T08:38:28.771586Z",
     "start_time": "2024-11-06T08:38:25.685027Z"
    }
   },
   "source": [
    "nlp = spacy.load('la_core_web_lg')"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "660e4b488203ea76",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-11-06T08:38:41.513421Z",
     "start_time": "2024-11-06T08:38:41.507700Z"
    }
   },
   "source": [
    "nlp.max_length # the maximal number of characters an input document can contain to be processed  "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "b43330a230a2ff84",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Spacy test"
   ]
  },
  {
   "cell_type": "code",
   "id": "78b894b2e11f2c5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-11-06T08:38:44.340585Z",
     "start_time": "2024-11-06T08:38:44.334859Z"
    }
   },
   "source": [
    "# what elements are in the pipeline?\n",
    "nlp.pipeline"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('senter', <spacy.pipeline.senter.SentenceRecognizer at 0x72bb27145d80>),\n",
       " ('normer', <function la_core_web_lg.functions.normer(doc)>),\n",
       " ('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x72bb27145180>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x72bb27145e40>),\n",
       " ('morphologizer',\n",
       "  <spacy.pipeline.morphologizer.Morphologizer at 0x72bb27145ea0>),\n",
       " ('trainable_lemmatizer',\n",
       "  <spacy.pipeline.edit_tree_lemmatizer.EditTreeLemmatizer at 0x72bb27145b40>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x72bb24bbc890>),\n",
       " ('lookup_lemmatizer',\n",
       "  <function la_core_web_lg.functions.make_lookup_lemmatizer_function(doc)>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x72bb24bbc7b0>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "893dfae9c690b086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:48:34.146393Z",
     "start_time": "2024-07-26T11:48:34.144019Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# check the functionilty with one famous classical texts\n",
    "vitruvius = \"Architecti Augusti est scientia pluribus disciplinis et variis eruditionibus ornata, quae ab ceteris artibus perficiuntur. Opera ea nascitur et fabrica et ratiocinatione.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ee2425d50e7ceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:48:34.621929Z",
     "start_time": "2024-07-26T11:48:34.595834Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sent = \"Architecti Augusti est scientia pluribus disciplinis et variis eruditionibus ornata, quae ab ceteris artibus perficiuntur. Opera ea nascitur et fabrica et ratiocinatione (Aristot.).\"\n",
    "doc = nlp(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e658d51e-2439-4d10-8553-b5500d3c03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecti architectus\n",
      "Augusti Augustus\n",
      "est sum\n",
      "scientia scientia\n",
      "pluribus plus\n",
      "disciplinis disciplina\n",
      "et et\n",
      "variis uarius\n",
      "eruditionibus eruditio\n",
      "ornata orno\n",
      ", ,\n",
      "quae qui\n",
      "ab ab\n",
      "ceteris ceterus\n",
      "artibus ars\n",
      "perficiuntur perficio\n",
      ". .\n",
      "Opera opera\n",
      "ea is\n",
      "nascitur nascor\n",
      "et et\n",
      "fabrica fabrica\n",
      "et et\n",
      "ratiocinatione ratiocinatio\n",
      "( (\n",
      "Aristot Aristot\n",
      ". .\n",
      ") )\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print(t.text, t.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0ea4c421ec4d82d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:48:35.054865Z",
     "start_time": "2024-07-26T11:48:35.052551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Architecti\n",
      "Lemma: architectus\n",
      "Part of Speech: VERB\n",
      "Is Stop Word: False\n",
      "Dependency: ROOT\n",
      "------\n",
      "Token: Augusti\n",
      "Lemma: Augustus\n",
      "Part of Speech: PROPN\n",
      "Is Stop Word: False\n",
      "Dependency: flat:name\n",
      "------\n",
      "Token: est\n",
      "Lemma: sum\n",
      "Part of Speech: AUX\n",
      "Is Stop Word: True\n",
      "Dependency: cop\n",
      "------\n",
      "Token: scientia\n",
      "Lemma: scientia\n",
      "Part of Speech: NOUN\n",
      "Is Stop Word: False\n",
      "Dependency: nsubj:pass\n",
      "------\n",
      "Token: pluribus\n",
      "Lemma: plus\n",
      "Part of Speech: DET\n",
      "Is Stop Word: False\n",
      "Dependency: det\n",
      "------\n",
      "Token: disciplinis\n",
      "Lemma: disciplina\n",
      "Part of Speech: NOUN\n",
      "Is Stop Word: False\n",
      "Dependency: obl\n",
      "------\n",
      "Token: et\n",
      "Lemma: et\n",
      "Part of Speech: CCONJ\n",
      "Is Stop Word: True\n",
      "Dependency: cc\n",
      "------\n",
      "Token: variis\n",
      "Lemma: uarius\n",
      "Part of Speech: ADJ\n",
      "Is Stop Word: False\n",
      "Dependency: amod\n",
      "------\n",
      "Token: eruditionibus\n",
      "Lemma: eruditio\n",
      "Part of Speech: NOUN\n",
      "Is Stop Word: False\n",
      "Dependency: obl\n",
      "------\n",
      "Token: ornata\n",
      "Lemma: orno\n",
      "Part of Speech: VERB\n",
      "Is Stop Word: False\n",
      "Dependency: conj\n",
      "------\n",
      "Token: ,\n",
      "Lemma: ,\n",
      "Part of Speech: PUNCT\n",
      "Is Stop Word: False\n",
      "Dependency: punct\n",
      "------\n",
      "Token: quae\n",
      "Lemma: qui\n",
      "Part of Speech: PRON\n",
      "Is Stop Word: True\n",
      "Dependency: nsubj:pass\n",
      "------\n",
      "Token: ab\n",
      "Lemma: ab\n",
      "Part of Speech: ADP\n",
      "Is Stop Word: True\n",
      "Dependency: case\n",
      "------\n",
      "Token: ceteris\n",
      "Lemma: ceterus\n",
      "Part of Speech: DET\n",
      "Is Stop Word: False\n",
      "Dependency: det\n",
      "------\n",
      "Token: artibus\n",
      "Lemma: ars\n",
      "Part of Speech: NOUN\n",
      "Is Stop Word: False\n",
      "Dependency: obl\n",
      "------\n",
      "Token: perficiuntur\n",
      "Lemma: perficio\n",
      "Part of Speech: VERB\n",
      "Is Stop Word: False\n",
      "Dependency: acl:relcl\n",
      "------\n",
      "Token: .\n",
      "Lemma: .\n",
      "Part of Speech: PUNCT\n",
      "Is Stop Word: False\n",
      "Dependency: punct\n",
      "------\n",
      "Token: Opera\n",
      "Lemma: opera\n",
      "Part of Speech: NOUN\n",
      "Is Stop Word: False\n",
      "Dependency: nsubj\n",
      "------\n",
      "Token: ea\n",
      "Lemma: is\n",
      "Part of Speech: PRON\n",
      "Is Stop Word: False\n",
      "Dependency: det\n",
      "------\n",
      "Token: nascitur\n",
      "Lemma: nascor\n",
      "Part of Speech: VERB\n",
      "Is Stop Word: False\n",
      "Dependency: ROOT\n",
      "------\n",
      "Token: et\n",
      "Lemma: et\n",
      "Part of Speech: CCONJ\n",
      "Is Stop Word: True\n",
      "Dependency: cc\n",
      "------\n",
      "Token: fabrica\n",
      "Lemma: fabrica\n",
      "Part of Speech: NOUN\n",
      "Is Stop Word: False\n",
      "Dependency: conj\n",
      "------\n",
      "Token: et\n",
      "Lemma: et\n",
      "Part of Speech: CCONJ\n",
      "Is Stop Word: True\n",
      "Dependency: cc\n",
      "------\n",
      "Token: ratiocinatione\n",
      "Lemma: ratiocinatio\n",
      "Part of Speech: NOUN\n",
      "Is Stop Word: False\n",
      "Dependency: conj\n",
      "------\n",
      "Token: .\n",
      "Lemma: .\n",
      "Part of Speech: PUNCT\n",
      "Is Stop Word: False\n",
      "Dependency: punct\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"Token: {token.text}\")\n",
    "    print(f\"Lemma: {token.lemma_}\")\n",
    "    print(f\"Part of Speech: {token.pos_}\")\n",
    "    print(f\"Is Stop Word: {token.is_stop}\")\n",
    "    print(f\"Dependency: {token.dep_}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb84a1d49a51346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:48:43.637217Z",
     "start_time": "2024-07-26T11:48:43.633806Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecti VERB architectus\n",
      "Augusti PROPN Augustus\n",
      "est AUX sum\n",
      "scientia NOUN scientia\n",
      "pluribus DET plus\n",
      "disciplinis NOUN disciplina\n",
      "et CCONJ et\n",
      "variis ADJ uarius\n",
      "eruditionibus NOUN eruditio\n",
      "ornata VERB orno\n",
      ", PUNCT ,\n",
      "quae PRON qui\n",
      "ab ADP ab\n",
      "ceteris DET ceterus\n",
      "artibus NOUN ars\n",
      "perficiuntur VERB perficio\n",
      ". PUNCT .\n",
      "Opera NOUN opera\n",
      "ea PRON is\n",
      "nascitur VERB nascor\n",
      "et CCONJ et\n",
      "fabrica NOUN fabrica\n",
      "et CCONJ et\n",
      "ratiocinatione NOUN ratiocinatio\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea28288817d77633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:48:44.277909Z",
     "start_time": "2024-07-26T11:48:44.274973Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_sents_lemmata = []\n",
    "for sent in doc.sents:\n",
    "    sent_lemmata = []\n",
    "    for token in sent:\n",
    "        if token.pos_ in [\"NOUN\", \"VERB\", \"ADJ\"]:\n",
    "            sent_lemmata.append(token.lemma_)\n",
    "    all_sents_lemmata.append(sent_lemmata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19c16bb19d2a9ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:48:45.525814Z",
     "start_time": "2024-07-26T11:48:45.522291Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Augusti,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dd6490a9a9ec239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:48:46.846887Z",
     "start_time": "2024-07-26T11:48:46.843838Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['architectus',\n",
       "  'scientia',\n",
       "  'disciplina',\n",
       "  'uarius',\n",
       "  'eruditio',\n",
       "  'orno',\n",
       "  'ars',\n",
       "  'perficio'],\n",
       " ['opera', 'nascor', 'fabrica', 'ratiocinatio']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sents_lemmata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d2965eb15bfa8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Apply spacy model on nocsemus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97c61720b1075454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T10:00:48.734967Z",
     "start_time": "2023-12-19T10:00:48.723239Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# s =  sddk.cloudSession(public_folder_url=\"https://sciencedata.dk/public/87394f685b79e7f1ebd4a7ead2b4941c/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94278d5-ca01-41a5-883a-108bd22f35ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "558597355b6a3a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T10:00:40.120972Z",
     "start_time": "2023-12-19T10:00:40.098383Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['913059.txt',\n",
       " '801742.txt',\n",
       " '888136.txt',\n",
       " '720097.txt',\n",
       " '663952.txt',\n",
       " '694621.txt',\n",
       " '868572.txt',\n",
       " '664562.txt',\n",
       " '747384.txt',\n",
       " '795562.txt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_list = os.listdir(\"/srv/data/tome/noscemus/noscemus_raw\")\n",
    "filenames_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d114405dfa7d859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T14:01:07.702351Z",
     "start_time": "2023-11-07T14:01:07.680734Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ids = [fn.partition(\".\")[0] for fn in filenames_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d794bd12937ef624",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T14:01:50.868997Z",
     "start_time": "2023-11-07T14:01:50.847979Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'801742.txt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c619596ad85f34",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756ffeb-e136-4569-8db2-4b5115653b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f70fe54a-fe31-4ddb-9c9f-eec1d9a8b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"/srv/data/tome/noscemus/noscemus_raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7017739fa2bda3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T14:02:05.155143Z",
     "start_time": "2023-11-07T14:02:04.027526Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "filename = filenames_list[20]\n",
    "with open(source_path + filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    rawtext = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dab80d9fee6f56cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T14:02:37.641142Z",
     "start_time": "2023-11-07T14:02:37.621277Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456272"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78857e2b46226e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T14:20:34.241023Z",
     "start_time": "2023-11-06T14:20:34.228665Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def text_cleaner(rawtext, lowercase=True):\n",
    "    cleantext = rawtext.replace(\"¬\\n\", \"\").replace(\"\\n\", \" \").replace(\"ß\", \"ss\").replace(\"ij\",\"ii\")\n",
    "    cleantext = \" \".join([t[0] + t[1:].lower() for t in cleantext.split()])\n",
    "    cleantext = re.sub(\"\\s\\s+\", \" \", cleantext)\n",
    "    cleantext = unidecode(cleantext)\n",
    "    cleantext = cleantext.replace(\"v\", \"u\").replace(\"V\", \"U\")\n",
    "    if lowercase:\n",
    "        cleantext = cleantext.lower()\n",
    "    return cleantext\n",
    "\n",
    "# lets encapsulate the cleaning and spacy pipeline application into one function\n",
    "def from_rawtext_to_doc(rawtext, lowertext=True):\n",
    "    cleantext = text_cleaner(rawtext, lowertext)\n",
    "    segment_len = 800000\n",
    "    if len(cleantext) > segment_len:\n",
    "        segment_docs = []\n",
    "        parts = cleantext[:segment_len].rpartition(\". \")\n",
    "        current_segment = parts[0] + parts[1]\n",
    "        segment_doc = nlp(current_segment)\n",
    "        segment_docs.append(segment_doc)\n",
    "        next_segment_beginning = parts[2]\n",
    "        for n in range(segment_len, len(cleantext), segment_len):\n",
    "            segment = cleantext[n:n+segment_len]\n",
    "            if len(segment) == segment_len:\n",
    "                parts = cleantext[n:n+segment_len].rpartition(\". \")\n",
    "                current_segment = parts[0] + parts[1]\n",
    "                segment_doc = nlp(next_segment_beginning + current_segment)\n",
    "                next_segment_beginning = parts[2]\n",
    "            else:\n",
    "                segment_doc = nlp(segment)\n",
    "            segment_docs.append(segment_doc)\n",
    "        doc = Doc.from_docs(segment_docs)\n",
    "    else:\n",
    "        doc = nlp(cleantext)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bccedcce4cda5b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T14:03:29.091223Z",
     "start_time": "2023-11-07T14:03:29.059206Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epistolarum ab eruditis uiris ad alb. hallerum scriparum pars i. latinae. uol. u. epistolae 133. ad 277. scriptae ab anno mdcclxi. ad annum mdcclxuiii. bernae. sumptibus societatis typographicae. 1774. lecturis s. hallerus. ad hoc uolumen idem semper est quod moneam, nimia nempe repeti encomia, quae delere neglexi morbo oppressus, & temporis penuria. epistolas etiam alias aliis majoris esse momenti fateor, & nonnullas illustrium alioquin uirorum, paulo minus propriis * 2 adno iu adnotationibus diuites. in aliis erat, quae, dum legeret doleret aliquis, ea, quantum potui, deleui. anno 1764. rupe discessi, & bernam repetii. unicum quod superest uolumen latinarum epistolarum finem faciet. d. d. 13. jun. 1774. epi epistolarum tabula gottlieb emanuel haller. ep. 133. 134. 136. 137. 138. 143. 145. 150. 151. 159. werner la chenal. ep. 135. 140. 147. 157. 203. 238. 248. 250. 251. 258. 260. 263. 267. 269. 272. 277. em. berdot, fil. ep. 139. 161. 193. 238. j. b morgagnus + ep.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantext = text_cleaner(rawtext[:1000])\n",
    "cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "567b276377594656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T14:03:39.723990Z",
     "start_time": "2023-11-07T14:03:39.709187Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EPISTOLARUM\\nAB\\nERUDITIS VIRIS\\nAD\\nALB. HALLERUM\\nSCRIPARUM\\nPARS I.\\nLatinae.\\nVOL. V.\\nEPISTOLAE 133. ad 277.\\nSCRIPTAE AB ANNO MDCCLXI.\\nAD ANNUM MDCCLXVIII.\\nBERNAE.\\nSumptibus Societatis Typographicae.\\n1774.\\n\\n\\nLECTURIS S.\\nHALLERUS.\\nAd hoc volumen idem semper est\\nquod moneam, nimia nempe repeti\\nencomia, quae delere neglexi morbo op¬\\npressus, & temporis penuria. Episto¬\\nlas etiam alias aliis majoris esse mo¬\\nmenti fateor, & nonnullas illustrium\\nalioquin virorum, paulo minus propriis\\n* 2\\nadno¬\\n\\n\\nIV\\n\\n\\nadnotationibus divites. In aliis erat,\\nquae, dum legeret doleret aliquis, ea,\\nquantum potui, delevi. Anno 1764. Ru¬\\npe discessi, & Bernam repetii. Unicum\\nquod superest volumen latinarum epi¬\\nstolarum finem faciet. D. d. 13. Jun.\\n1774.\\nEPI¬\\n\\n\\nEPISTOLARUM\\nTABULA\\nGOTTLIEB EMANUEL HALLER. Ep. 133. 134.\\n136. 137. 138. 143. 145. 150. 151. 159.\\nWERNER LA CHENAL. Ep. 135. 140. 147. 157.\\n203. 238. 248. 250. 251. 258. 260. 263. 267.\\n269. 272. 277.\\nEM. BERDOT, Fil. Ep. 139. 161. 193. 238.\\nJ. B MORGAGNUS † Ep.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawtext[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "506e2c0c66c267d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T14:03:55.721139Z",
     "start_time": "2023-11-07T14:03:55.099121Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epistolarum ab eruditis uiris ad alb. hallerum scriparum pars i. latinae. uol. u. epistolae 133. ad 277. scriptae ab anno mdcclxi. ad annum mdcclxuiii. bernae. sumptibus societatis typographicae. 1774. lecturis s. hallerus. ad hoc uolumen idem semper est quod moneam, nimia nempe repeti encomia, quae delere neglexi morbo oppressus, & temporis penuria. epistolas etiam alias aliis majoris esse momenti fateor, & nonnullas illustrium alioquin uirorum, paulo minus propriis * 2 adno iu adnotationibus diuites. in aliis erat, quae, dum legeret doleret aliquis, ea, quantum potui, deleui. anno 1764. rupe discessi, & bernam repetii. unicum quod superest uolumen latinarum epistolarum finem faciet. d. d. 13. jun. 1774. epi epistolarum tabula gottlieb emanuel haller. ep. 133. 134. 136. 137. 138. 143. 145. 150. 151. 159. werner la chenal. ep. 135. 140. 147. 157. 203. 238. 248. 250. 251. 258. 260. 263. 267. 269. 272. 277. em. berdot, fil. ep. 139. 161. 193. 238. j. b morgagnus + ep."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(cleantext[:10000])\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbc441980b95472a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T14:05:26.323491Z",
     "start_time": "2023-11-07T14:05:26.309660Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epistola NOUN\n",
      "ab ADP\n",
      "erudio VERB\n",
      "uir NOUN\n",
      "ad ADP\n",
      "alb ADV\n",
      ". PUNCT\n",
      "halle NOUN\n",
      "scripae NOUN\n",
      "pars NOUN\n",
      "i. PROPN\n",
      "latinus ADJ\n",
      ". PUNCT\n",
      " ADV\n",
      " ADJ\n",
      "epistola NOUN\n",
      "133 NUM\n",
      ". PUNCT\n",
      "ad ADP\n",
      "277 NUM\n",
      ". PUNCT\n",
      "scripno VERB\n",
      "ab ADP\n",
      "annus NOUN\n",
      "mdcclxius VERB\n",
      ". PUNCT\n",
      "ad ADP\n",
      "annus NOUN\n",
      " ADJ\n",
      ". PUNCT\n",
      "bernus ADJ\n",
      ". PUNCT\n",
      "sumptus NOUN\n",
      "societas NOUN\n",
      "typographicus ADJ\n",
      ". PUNCT\n",
      "1774 X\n",
      ". PUNCT\n",
      "lego NOUN\n",
      "s. ADJ\n",
      "allerus NOUN\n",
      ". PUNCT\n",
      "ad ADP\n",
      "hic DET\n",
      "uolumen NOUN\n",
      "idem DET\n",
      "semper ADV\n",
      "sum AUX\n",
      "quod SCONJ\n",
      "moneo VERB\n",
      ", PUNCT\n",
      "nimius ADJ\n",
      "nempe ADV\n",
      "repeto VERB\n",
      "encomium NOUN\n",
      ", PUNCT\n",
      "qui PRON\n",
      "deleo VERB\n",
      "neglego VERB\n",
      "morbus NOUN\n",
      "opprimo VERB\n",
      ", PUNCT\n",
      "& PUNCT\n",
      "tempus NOUN\n",
      "penuria NOUN\n",
      ". PUNCT\n",
      "epistola NOUN\n",
      "etiam ADV\n",
      "alius DET\n",
      "alius DET\n",
      "maior DET\n",
      "sum NOUN\n",
      "momentum NOUN\n",
      "fateor VERB\n",
      ", PUNCT\n",
      "& PUNCT\n",
      "nonnullus ADJ\n",
      "illustris ADJ\n",
      "alioqui ADV\n",
      "uir NOUN\n",
      ", PUNCT\n",
      "paulus ADV\n",
      "paruus ADV\n",
      "proprius ADJ\n",
      "* PUNCT\n",
      "2 NUM\n",
      "adno NOUN\n",
      "iu NUM\n",
      "adnotatio NOUN\n",
      "diues ADJ\n",
      ". PUNCT\n",
      "in ADP\n",
      "alius DET\n",
      "sum AUX\n",
      ", PUNCT\n",
      "qui PRON\n",
      ", PUNCT\n",
      "dum SCONJ\n",
      "lego VERB\n",
      "doleo VERB\n",
      "aliquis PRON\n",
      ", PUNCT\n",
      "is PRON\n",
      ", PUNCT\n",
      "quantum ADV\n",
      "possum VERB\n",
      ", PUNCT\n",
      "deleo VERB\n",
      ". PUNCT\n",
      "annus NOUN\n",
      "1764s X\n",
      ". PUNCT\n",
      "rupes NOUN\n",
      "discedo VERB\n",
      ", PUNCT\n",
      "& PUNCT\n",
      "berna NOUN\n",
      "repetium NOUN\n",
      ". PUNCT\n",
      "unicus ADJ\n",
      "qui PRON\n",
      "supersum VERB\n",
      "uolumen NOUN\n",
      "latinus ADJ\n",
      "epistola NOUN\n",
      "finis NOUN\n",
      "facio VERB\n",
      ". PUNCT\n",
      " ADJ\n",
      "d. PROPN\n",
      "13 NUM\n",
      ". PUNCT\n",
      " VERB\n",
      ". PUNCT\n",
      "1774 PUNCT\n",
      ". PUNCT\n",
      "epi NUM\n",
      "epistola NOUN\n",
      "tabula NOUN\n",
      "gottliebs NOUN\n",
      "emanuel CCONJ\n",
      "haaller NOUN\n",
      ". PUNCT\n",
      "epitulum NOUN\n",
      ". PUNCT\n",
      "133 NUM\n",
      ". PUNCT\n",
      "134 NUM\n",
      ". PUNCT\n",
      "136 NUM\n",
      ". PUNCT\n",
      "137 NUM\n",
      ". PUNCT\n",
      "138 NUM\n",
      ". PUNCT\n",
      "143 ADJ\n",
      ". PUNCT\n",
      "145 NUM\n",
      ". PUNCT\n",
      "150 NUM\n",
      ". PUNCT\n",
      "151 NUM\n",
      ". PUNCT\n",
      "159 NUM\n",
      ". PUNCT\n",
      " ADP\n",
      "la ADP\n",
      "chenal NOUN\n",
      ". PUNCT\n",
      "epitulum NOUN\n",
      ". PUNCT\n",
      "135 NUM\n",
      ". PUNCT\n",
      "140 NUM\n",
      ". PUNCT\n",
      "147estis NUM\n",
      ". PUNCT\n",
      "157 NUM\n",
      ". PUNCT\n",
      " ADJ\n",
      ". PUNCT\n",
      "238 ADJ\n",
      ". PUNCT\n",
      "248 NUM\n",
      ". PUNCT\n",
      "250 NUM\n",
      ". PUNCT\n",
      "251 NUM\n",
      ". PUNCT\n",
      "258 NUM\n",
      ". PUNCT\n",
      "260 ADJ\n",
      ". PUNCT\n",
      "263 NUM\n",
      ". PUNCT\n",
      "267 NUM\n",
      ". PUNCT\n",
      "269 ADJ\n",
      ". PUNCT\n",
      "272 NUM\n",
      ". PUNCT\n",
      "277 NUM\n",
      ". PUNCT\n",
      " NOUN\n",
      ". PUNCT\n",
      " NOUN\n",
      ", PUNCT\n",
      "fil NOUN\n",
      ". PUNCT\n",
      "epitulum NOUN\n",
      ". PUNCT\n",
      "139 NUM\n",
      ". PUNCT\n",
      "161 NUM\n",
      ". PUNCT\n",
      "193 ADJ\n",
      ". PUNCT\n",
      "238 NUM\n",
      ". PUNCT\n",
      " ADV\n",
      "b ADP\n",
      "morgagnus ADJ\n",
      "+ PUNCT\n",
      "epesis NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faca3312f480753",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Applying the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b86d9ce45097bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T07:32:58.064106Z",
     "start_time": "2023-11-07T07:32:58.052336Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames_list)"
   ]
  },
  {
   "cell_type": "code",
   "id": "153977c0-9a43-421f-9c2f-39d22ca57f34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T08:39:54.480429Z",
     "start_time": "2024-11-06T08:39:54.476167Z"
    }
   },
   "source": [
    "target_path = \"/srv/data/tome/noscemus/sents_data/\"\n",
    "try:\n",
    "    os.mkdir(target_path)\n",
    "except:\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7df1a4ff-dbb5-4999-bb0a-edd106a45ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noscemus_raw',\n",
       " 'NOSCEMUS FULL',\n",
       " 'lemmatized_sents',\n",
       " 'sents_data_lower',\n",
       " 'test2',\n",
       " 'test',\n",
       " 'NOSCEMUS_FULL.zip',\n",
       " 'sents_data']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"/srv/data/tome/noscemus/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "19ce9aabe1147398",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T07:26:30.441632Z",
     "start_time": "2023-11-07T07:26:29.301590Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "CPU times: user 2h 21min 42s, sys: 7min 7s, total: 2h 28min 49s\n",
      "Wall time: 2h 28min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n, filename in enumerate(filenames_list):\n",
    "    id = filename.rpartition(\".txt\")[0]\n",
    "    with open(source_path + filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        rawtext = f.read()\n",
    "    doc = from_rawtext_to_doc(rawtext)\n",
    "    doc_sentdata = [(sent.text, [(t.text, t.lemma_, t.pos_, (t.idx - sent[0].idx, t.idx - sent[0].idx + len(t))) for t in sent]) for sent in doc.sents]\n",
    "    with open(target_path + id + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(doc_sentdata, f)\n",
    "    if n in range(0, len(filenames_list), 50): # print out the progress each 50 files...\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89302cea-d8a9-46c8-88bc-b7be3f9bebd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['725075.pickle',\n",
       " '928138.pickle',\n",
       " '985903.pickle',\n",
       " '733505.pickle',\n",
       " '739101.pickle',\n",
       " '702145.pickle',\n",
       " '906214.pickle',\n",
       " '902259.pickle',\n",
       " '901017.pickle',\n",
       " '904418.pickle']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(target_path)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f10029ef-217e-4106-a5c7-0d7015dd5ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(target_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85ea89d5-b3e2-4b4a-979b-2fcad06c8915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tarditis uerum est ad gratissimas tuas litteras respondissem, nisi nouum a Te beneficium in me redundasset.',\n",
       "  [('Tarditis', 'Tarditus', 'PROPN', (0, 8)),\n",
       "   ('uerum', 'uerus', 'ADJ', (9, 14)),\n",
       "   ('est', 'sum', 'AUX', (15, 18)),\n",
       "   ('ad', 'ad', 'ADP', (19, 21)),\n",
       "   ('gratissimas', 'gratissimus', 'ADJ', (22, 33)),\n",
       "   ('tuas', 'tuus', 'DET', (34, 38)),\n",
       "   ('litteras', 'littera', 'NOUN', (39, 47)),\n",
       "   ('respondissem', 'respondeo', 'VERB', (48, 60)),\n",
       "   (',', ',', 'PUNCT', (60, 61)),\n",
       "   ('nisi', 'nisi', 'SCONJ', (62, 66)),\n",
       "   ('nouum', 'nouus', 'ADJ', (67, 72)),\n",
       "   ('a', 'ab', 'ADP', (73, 74)),\n",
       "   ('Te', 'tu', 'PRON', (75, 77)),\n",
       "   ('beneficium', 'beneficium', 'NOUN', (78, 88)),\n",
       "   ('in', 'in', 'ADP', (89, 91)),\n",
       "   ('me', 'ego', 'PRON', (92, 94)),\n",
       "   ('redundasset', 'redundo', 'VERB', (95, 106)),\n",
       "   ('.', '.', 'PUNCT', (106, 107))]),\n",
       " ('Academiae nempe scientiarum Parisinae placuit me immeritum iis adscribere, quibus cum ipsi est litterarum commercium.',\n",
       "  [('Academiae', 'Academia', 'NOUN', (0, 9)),\n",
       "   ('nempe', 'nempe', 'PART', (10, 15)),\n",
       "   ('scientiarum', 'scientia', 'NOUN', (16, 27)),\n",
       "   ('Parisinae', 'Parisina', 'PROPN', (28, 37)),\n",
       "   ('placuit', 'placeo', 'VERB', (38, 45)),\n",
       "   ('me', 'ego', 'PRON', (46, 48)),\n",
       "   ('immeritum', 'immeritus', 'NOUN', (49, 58)),\n",
       "   ('iis', 'is', 'PRON', (59, 62)),\n",
       "   ('adscribere', 'adscribo', 'VERB', (63, 73)),\n",
       "   (',', ',', 'PUNCT', (73, 74)),\n",
       "   ('quibus', 'qui', 'PRON', (75, 81)),\n",
       "   ('cum', 'cum', 'ADP', (82, 85)),\n",
       "   ('ipsi', 'ipse', 'DET', (86, 90)),\n",
       "   ('est', 'sum', 'AUX', (91, 94)),\n",
       "   ('litterarum', 'littera', 'NOUN', (95, 105)),\n",
       "   ('commercium', 'commercium', 'NOUN', (106, 116)),\n",
       "   ('.', '.', 'PUNCT', (116, 117))]),\n",
       " ('Honor iste mihi nudius tertius decretus fuit, quem Tibi unice debeo.',\n",
       "  [('Honor', 'honor', 'NOUN', (0, 5)),\n",
       "   ('iste', 'iste', 'DET', (6, 10)),\n",
       "   ('mihi', 'ego', 'PRON', (11, 15)),\n",
       "   ('nudius', 'nudius', 'ADV', (16, 22)),\n",
       "   ('tertius', 'tertius', 'ADJ', (23, 30)),\n",
       "   ('decretus', 'decreo', 'VERB', (31, 39)),\n",
       "   ('fuit', 'sum', 'AUX', (40, 44)),\n",
       "   (',', ',', 'PUNCT', (44, 45)),\n",
       "   ('quem', 'qui', 'PRON', (46, 50)),\n",
       "   ('Tibi', 'tu', 'PRON', (51, 55)),\n",
       "   ('unice', 'unicus', 'ADV', (56, 61)),\n",
       "   ('debeo', 'debeo', 'VERB', (62, 67)),\n",
       "   ('.', '.', 'PUNCT', (67, 68))]),\n",
       " ('Gaudeo hoc titulo uti, quod liber mihi jam sit ad Academiae conuentum aditus, & diarium de mense in mensem accipies de rebus in Academia actis, ut pateat, me sedulo adfuisse.',\n",
       "  [('Gaudeo', 'gaudeo', 'VERB', (0, 6)),\n",
       "   ('hoc', 'hic', 'DET', (7, 10)),\n",
       "   ('titulo', 'titulus', 'NOUN', (11, 17)),\n",
       "   ('uti', 'utor', 'VERB', (18, 21)),\n",
       "   (',', ',', 'PUNCT', (21, 22)),\n",
       "   ('quod', 'qui', 'SCONJ', (23, 27)),\n",
       "   ('liber', 'liber', 'NOUN', (28, 33)),\n",
       "   ('mihi', 'ego', 'PRON', (34, 38)),\n",
       "   ('jam', 'jam', 'ADV', (39, 42)),\n",
       "   ('sit', 'sum', 'AUX', (43, 46)),\n",
       "   ('ad', 'ad', 'ADP', (47, 49)),\n",
       "   ('Academiae', 'Academia', 'PROPN', (50, 59)),\n",
       "   ('conuentum', 'conuenio', 'VERB', (60, 69)),\n",
       "   ('aditus', 'aditus', 'NOUN', (70, 76)),\n",
       "   (',', ',', 'PUNCT', (76, 77)),\n",
       "   ('&', '&', 'PUNCT', (78, 79)),\n",
       "   ('diarium', 'diarium', 'NOUN', (80, 87)),\n",
       "   ('de', 'de', 'ADP', (88, 90)),\n",
       "   ('mense', 'mensis', 'NOUN', (91, 96)),\n",
       "   ('in', 'in', 'ADP', (97, 99)),\n",
       "   ('mensem', 'mensis', 'NOUN', (100, 106)),\n",
       "   ('accipies', 'accipio', 'VERB', (107, 115)),\n",
       "   ('de', 'de', 'ADP', (116, 118)),\n",
       "   ('rebus', 'res', 'NOUN', (119, 124)),\n",
       "   ('in', 'in', 'ADP', (125, 127)),\n",
       "   ('Academia', 'Academia', 'PROPN', (128, 136)),\n",
       "   ('actis', 'ago', 'VERB', (137, 142)),\n",
       "   (',', ',', 'PUNCT', (142, 143)),\n",
       "   ('ut', 'ut', 'SCONJ', (144, 146)),\n",
       "   ('pateat', 'pateo', 'VERB', (147, 153)),\n",
       "   (',', ',', 'PUNCT', (153, 154)),\n",
       "   ('me', 'ego', 'PRON', (155, 157)),\n",
       "   ('sedulo', 'sedulus', 'ADV', (158, 164)),\n",
       "   ('adfuisse', 'adsum', 'VERB', (165, 173)),\n",
       "   ('.', '.', 'PUNCT', (173, 174))]),\n",
       " ('Quae porro mihi dederunt Parisini Tibi reddenda, die 23.',\n",
       "  [('Quae', 'qui', 'PRON', (0, 4)),\n",
       "   ('porro', 'porro', 'ADV', (5, 10)),\n",
       "   ('mihi', 'ego', 'PRON', (11, 15)),\n",
       "   ('dederunt', 'do', 'VERB', (16, 24)),\n",
       "   ('Parisini', 'Parisinus', 'PROPN', (25, 33)),\n",
       "   ('Tibi', 'tu', 'PRON', (34, 38)),\n",
       "   ('reddenda', 'reddo', 'VERB', (39, 47)),\n",
       "   (',', ',', 'PUNCT', (47, 48)),\n",
       "   ('die', 'dies', 'NOUN', (49, 52)),\n",
       "   ('23', '23', 'NUM', (53, 55)),\n",
       "   ('.', '.', 'PUNCT', (55, 56))]),\n",
       " ('Decembr. ut scripsi Bernam misi, Thierrium ut quae haberet adderet, compellaui, sed negauit se quidquam habere Tibi mittendum.',\n",
       "  [('Decembr.', 'decembr.', 'SCONJ', (0, 8)),\n",
       "   ('ut', 'ut', 'SCONJ', (9, 11)),\n",
       "   ('scripsi', 'scribo', 'VERB', (12, 19)),\n",
       "   ('Bernam', 'Berna', 'PROPN', (20, 26)),\n",
       "   ('misi', 'mitto', 'VERB', (27, 31)),\n",
       "   (',', ',', 'PUNCT', (31, 32)),\n",
       "   ('Thierrium', 'Thierrius', 'PROPN', (33, 42)),\n",
       "   ('ut', 'ut', 'SCONJ', (43, 45)),\n",
       "   ('quae', 'qui', 'PRON', (46, 50)),\n",
       "   ('haberet', 'habeo', 'VERB', (51, 58)),\n",
       "   ('adderet', 'addo', 'VERB', (59, 66)),\n",
       "   (',', ',', 'PUNCT', (66, 67)),\n",
       "   ('compellaui', 'compello', 'VERB', (68, 78)),\n",
       "   (',', ',', 'PUNCT', (78, 79)),\n",
       "   ('sed', 'sed', 'CCONJ', (80, 83)),\n",
       "   ('negauit', 'nego', 'VERB', (84, 91)),\n",
       "   ('se', 'sui', 'PRON', (92, 94)),\n",
       "   ('quidquam', 'quisquam', 'PRON', (95, 103)),\n",
       "   ('habere', 'habeo', 'VERB', (104, 110)),\n",
       "   ('Tibi', 'Tu', 'PRON', (111, 115)),\n",
       "   ('mittendum', 'mitto', 'VERB', (116, 125)),\n",
       "   ('.', '.', 'PUNCT', (125, 126))]),\n",
       " ('Quae de Physiologia addis ita exequar, ut exemplaria ipse a Dauidio petam, nominibusque quibus inscripsisti reddam.',\n",
       "  [('Quae', 'qui', 'PRON', (0, 4)),\n",
       "   ('de', 'de', 'ADP', (5, 7)),\n",
       "   ('Physiologia', 'physiologia', 'PROPN', (8, 19)),\n",
       "   ('addis', 'addo', 'VERB', (20, 25)),\n",
       "   ('ita', 'ita', 'ADV', (26, 29)),\n",
       "   ('exequar', 'exequor', 'VERB', (30, 37)),\n",
       "   (',', ',', 'PUNCT', (37, 38)),\n",
       "   ('ut', 'ut', 'SCONJ', (39, 41)),\n",
       "   ('exemplaria', 'exemplar', 'NOUN', (42, 52)),\n",
       "   ('ipse', 'ipse', 'DET', (53, 57)),\n",
       "   ('a', 'ab', 'ADP', (58, 59)),\n",
       "   ('Dauidio', 'Dauidium', 'PROPN', (60, 67)),\n",
       "   ('petam', 'peto', 'VERB', (68, 73)),\n",
       "   (',', ',', 'PUNCT', (73, 74)),\n",
       "   ('nominibus', 'nomen', 'NOUN', (75, 84)),\n",
       "   ('que', 'que', 'CCONJ', (84, 87)),\n",
       "   ('quibus', 'qui', 'PRON', (88, 94)),\n",
       "   ('inscripsisti', 'inscribo', 'VERB', (95, 107)),\n",
       "   ('reddam', 'reddo', 'VERB', (108, 114)),\n",
       "   ('.', '.', 'PUNCT', (114, 115))]),\n",
       " ('Gratissimae certe erunt his eruditissimis uiris strenae.',\n",
       "  [('Gratissimae', '', 'ADJ', (0, 11)),\n",
       "   ('certe', 'certe', 'ADV', (12, 17)),\n",
       "   ('erunt', 'sum', 'AUX', (18, 23)),\n",
       "   ('his', 'hic', 'DET', (24, 27)),\n",
       "   ('eruditissimis', 'eruditissimus', 'ADJ', (28, 41)),\n",
       "   ('uiris', 'uir', 'NOUN', (42, 47)),\n",
       "   ('strenae', 'strenus', 'ADJ', (48, 55)),\n",
       "   ('.', '.', 'PUNCT', (55, 56))]),\n",
       " ('Thierrio optimo meo & fido amico maxima & insignis lis est cum quodam Des Caunets, uel potius Bordeu, hujus enim instigatione prior contra Thierrium uehementem & injuriosum libellum scripsit, occasione thermarum de Bagneres & A de Tom.',\n",
       "  [('Thierrio', 'Thierrius', 'PROPN', (0, 8)),\n",
       "   ('optimo', 'optimus', 'ADJ', (9, 15)),\n",
       "   ('meo', 'meus', 'DET', (16, 19)),\n",
       "   ('&', '&', 'PUNCT', (20, 21)),\n",
       "   ('fido', 'fido', 'VERB', (22, 26)),\n",
       "   ('amico', 'amicus', 'NOUN', (27, 32)),\n",
       "   ('maxima', 'maximus', 'ADJ', (33, 39)),\n",
       "   ('&', '&', 'PUNCT', (40, 41)),\n",
       "   ('insignis', 'insignis', 'ADJ', (42, 50)),\n",
       "   ('lis', 'lis', 'NOUN', (51, 54)),\n",
       "   ('est', 'sum', 'AUX', (55, 58)),\n",
       "   ('cum', 'cum', 'ADP', (59, 62)),\n",
       "   ('quodam', 'quidam', 'DET', (63, 69)),\n",
       "   ('Des', 'do', 'NOUN', (70, 73)),\n",
       "   ('Caunets', 'caunets', 'PROPN', (74, 81)),\n",
       "   (',', ',', 'PUNCT', (81, 82)),\n",
       "   ('uel', 'uel', 'CCONJ', (83, 86)),\n",
       "   ('potius', 'potior', 'ADV', (87, 93)),\n",
       "   ('Bordeu', '', 'PROPN', (94, 100)),\n",
       "   (',', ',', 'PUNCT', (100, 101)),\n",
       "   ('hujus', 'husjus', 'DET', (102, 107)),\n",
       "   ('enim', 'enim', 'PART', (108, 112)),\n",
       "   ('instigatione', 'instigatio', 'NOUN', (113, 125)),\n",
       "   ('prior', 'prior', 'ADJ', (126, 131)),\n",
       "   ('contra', 'contra', 'ADP', (132, 138)),\n",
       "   ('Thierrium', 'Thierrius', 'PROPN', (139, 148)),\n",
       "   ('uehementem', 'uehemens', 'ADJ', (149, 159)),\n",
       "   ('&', '&', 'PUNCT', (160, 161)),\n",
       "   ('injuriosum', 'injuriosus', 'ADJ', (162, 172)),\n",
       "   ('libellum', 'libellus', 'NOUN', (173, 181)),\n",
       "   ('scripsit', 'scribo', 'VERB', (182, 190)),\n",
       "   (',', ',', 'PUNCT', (190, 191)),\n",
       "   ('occasione', 'occasio', 'NOUN', (192, 201)),\n",
       "   ('thermarum', 'therma', 'NOUN', (202, 211)),\n",
       "   ('de', 'de', 'ADP', (212, 214)),\n",
       "   ('Bagneres', 'Bagnes', 'ADJ', (215, 223)),\n",
       "   ('&', '&', 'PUNCT', (224, 225)),\n",
       "   ('A', 'a', 'NOUN', (226, 227)),\n",
       "   ('de', 'de', 'ADP', (228, 230)),\n",
       "   ('Tom', 'Tomicus', 'PROPN', (231, 234)),\n",
       "   ('.', '.', 'PUNCT', (234, 235))]),\n",
       " ('U. Comm.',\n",
       "  [('U.', 'u.', 'PUNCT', (0, 2)),\n",
       "   ('Comm', 'comm', 'NOUN', (3, 7)),\n",
       "   ('.', '.', 'PUNCT', (7, 8))])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test: loading back individual file\n",
    "sents_data = pickle.load(open(target_path + filenames_list[20].replace(\".txt\", \".pickle\"), \"rb\"))\n",
    "sents_data[100:110]"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T09:04:24.892406Z",
     "start_time": "2024-11-06T09:04:24.887942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source_pickles = \"/srv/data/tome/noscemus/sents_data/\"\n",
    "target_jsons = \"/srv/data/tome/noscemus/sents_data_jsons/\"\n",
    "try:\n",
    "    os.mkdir(target_jsons)\n",
    "except:\n",
    "    pass"
   ],
   "id": "3673ac139241f316",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T09:12:14.176838Z",
     "start_time": "2024-11-06T09:04:31.077937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for fn in os.listdir(source_pickles):\n",
    "    doc_id =  fn.rpartition(\".\")[0]\n",
    "    with open(source_pickles + fn, \"rb\") as f:\n",
    "        sents_data = pickle.load(f)\n",
    "    sents_data_updated = []\n",
    "    for sent_n, (sent_text, sent_data) in enumerate(sents_data):\n",
    "        sents_data_updated.append((doc_id, sent_n, sent_text, sent_data))\n",
    "    with open(target_jsons + doc_id + \".json\", \"w\") as f:\n",
    "        json.dump(sents_data_updated, f)"
   ],
   "id": "3abe004a748b7d29",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7bdcd4a4383b37d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bbfbd9314fbbf478"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77f1a073-14bd-4606-b8c0-b167d90dde62",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = \"/srv/data/tome/noscemus/sents_data_lower/\"\n",
    "try:\n",
    "    os.mkdir(target_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae686654-c56b-4a6b-a522-759963f428f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready = os.listdir(target_path)\n",
    "len(ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2562f46-8b88-4fef-9028-747f655c45d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "CPU times: user 48min 52s, sys: 2min 26s, total: 51min 18s\n",
      "Wall time: 51min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n, filename in enumerate(filenames_list):\n",
    "    if filename.replace(\".txt\", \".pickle\") not in ready:\n",
    "        id = filename.rpartition(\".txt\")[0]\n",
    "        with open(source_path + filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            rawtext = f.read()\n",
    "        doc = from_rawtext_to_doc(rawtext)\n",
    "        doc_sentdata = [(sent.text, [(t.text, t.lemma_, t.pos_, (t.idx - sent[0].idx, t.idx - sent[0].idx + len(t))) for t in sent]) for sent in doc.sents]\n",
    "        with open(target_path + id + \".pickle\", \"wb\") as f:\n",
    "            pickle.dump(doc_sentdata, f)\n",
    "        if n in range(0, len(filenames_list), 50): # print out the progress each 50 files...\n",
    "            print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035955f-0cbc-498f-ad79-183380f8e47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf07c3-c511-4d4a-b5b3-3521ecb6089f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d81efd-e526-4849-aeee-7034780fd8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c42d9-2888-4ee8-a1bf-d526e7500a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "435a0323-fa43-4085-8cac-c4067358ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = target_path\n",
    "target_path = \"/srv/data/tome/noscemus/lemmatized_sents/\"\n",
    "try:\n",
    "    os.mkdir(target_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9513e54f-068a-4d3a-974a-d038f3faa413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['725075.pickle',\n",
       " '928138.pickle',\n",
       " '985903.pickle',\n",
       " '733505.pickle',\n",
       " '739101.pickle',\n",
       " '702145.pickle',\n",
       " '906214.pickle',\n",
       " '902259.pickle',\n",
       " '901017.pickle',\n",
       " '904418.pickle']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns = os.listdir(source_path)\n",
    "fns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "27c5c0e9-870e-4938-8dc8-c8ec5e4e76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in fns:\n",
    "    lemmatized_sents = []\n",
    "    sents_data = pickle.load(open(source_path + fn, \"rb\"))\n",
    "    for (sent_text, sent_data) in sents_data:\n",
    "        lemmasent = []\n",
    "        for wordform, lemma, tag, position in sent_data:\n",
    "            if tag in [\"NOUN\", \"PROPN\", \"ADJ\", \"VERB\"]:\n",
    "                lemmasent.append(lemma)\n",
    "        lemmatized_sents.append(\" \".join(lemmasent) + \"\\n\")\n",
    "    with open(target_path + fn.replace(\".pickle\", \".txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(lemmatized_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8db5fe-2a63-4761-a145-7e82373c93d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latin_global_kernel",
   "language": "python",
   "name": "latin_global_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
